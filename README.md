# Моя первая попытка в скрапинг w/ Playwright

Небольшой учебный проект: беру список товаров из Excel, ищу по ним сайты и пытаюсь вытащить характеристики в структурированный JSON.

## Как это работает

1. Поочерёдно читаю товары из Excel (таблица вида: `бренд | артикул | наименование`).
2. Для каждого товара нахожу 5 сайтов/страниц с этим товаром.
3. Захожу на страницы и при удачном парсинге сохраняю результат.
4. Сохраняю результат в JSON-файл.

## Формат входных данных (Excel)

Пример структуры таблицы:

| бренд | артикул | наименование |
|------|---------|--------------|
| Medtronic | 10BA30D | 10BA30D Круглый бор с мелким алмазным напылением, длина 10 см, диаметр головки 3.0 мм |

> Названия колонок могут быть любыми — главное, чтобы в проекте были корректно сопоставлены поля “бренд / артикул / наименование” и чтобы поля были в 1 строчке(на самом деле можно было не писать эти поля(но когда я это делал видимо я был другого мнения), т.к они излишни, но я уже реализовал чтение экселя  с пропуском первой строчки). Моковый эксель(mockExcel) можно найти в корне репозитория 

## Формат результата (JSON)

На каждую позицию формируется объект примерно такого вида(результат парсинга товаров из mockExcel можно найти в src/results.json):

```json
{
    "Номер позиции из файла": 0,
    "Наименование": "Medtronic 10BAD30D",
    "Описание": "10BA30D Круглый бор с мелким алмазным напылением, длина 10 см, диаметр головки 3.0 мм",
    "Характеристики": {
        "Артикул": "10BA30D",
        "Ширина": "7 см",
        "Высота": "3 см",
        "Глубина": "15 см",
        "Вес": "10 гр",
        "Стерильность": "Да"
    },
}
```
## запуск
установи зависимости npm install, далее npm run dev
